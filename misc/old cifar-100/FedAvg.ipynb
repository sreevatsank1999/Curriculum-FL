{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedAvg\n",
    "\n",
    "Vanila FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import os \n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU: 0\n",
      "GPU Name: GeForce GTX 1080 Ti\n",
      "Number of GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Current GPU: {torch.cuda.current_device()}')\n",
    "print(f'GPU Name: {torch.cuda.get_device_name()}')\n",
    "print(f'Number of GPUs: {torch.cuda.device_count()}')\n",
    "torch.cuda.set_device(1) ## Setting cuda on GPU:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args: \n",
    "    num_users = 2\n",
    "    seed = 1\n",
    "    gpu = 1\n",
    "    \n",
    "    ## CIFAR-10 has 50000 training images (5000 per class), 10 classes, 10000 test images (1000 per class)\n",
    "    ## CIFAR-100 has 50000 training images (500 per class), 100 classes, 10000 test images (100 per class)\n",
    "    ## MNIST has 60000 training images (min: 5421, max: 6742 per class), 10000 test images (min: 892, max: 1135\n",
    "    ## per class) --> in the code we fixed 5000 training image per class, and 900 test image per class to be \n",
    "    ## consistent with CIFAR-10 \n",
    "    \n",
    "    ## CIFAR-10 Non-IID 250 samples per label for 2 class non-iid is the benchmark (500 samples for each client)\n",
    "    \n",
    "    nsample_pc = 250  ## number of samples per class for each client \n",
    "    nclass = 2        ## number of classes or shards for each client\n",
    "    model = 'resnet9' ## options: lenet5\n",
    "    dataset = 'cifar100'  ## options: mnist, cifar10, cifar100\n",
    "    datadir = '../data/'\n",
    "    logdir = '../logs/'\n",
    "    partition = 'noniid-#label20'\n",
    "    alg = 'cluster_fl'\n",
    "    savedir = '../save/'\n",
    "    beta = 0.1\n",
    "    local_view = True\n",
    "    batch_size= 10\n",
    "    noise = 0\n",
    "    noise_type = 'level'\n",
    "    \n",
    "    rounds = 30\n",
    "    frac = 0.1\n",
    "    local_bs = 10\n",
    "    local_ep = 5\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    \n",
    "    cluster_alpha = 3.5\n",
    "    nclasses = 10 \n",
    "    nsamples_shared = 2500\n",
    "    n_basis = 3\n",
    "    linkage = 'average'\n",
    "    \n",
    "    noniid = True\n",
    "    noniid_iid = False\n",
    "    shard = True\n",
    "    label = False\n",
    "    split_test = False\n",
    "    \n",
    "    print_freq = 50\n",
    "    \n",
    "    load_initial = ''\n",
    "    \n",
    "args = Args()\n",
    "\n",
    "torch.cuda.set_device(args.gpu) ## Setting cuda on GPU \n",
    "#torch.manual_seed(args.seed)\n",
    "#np.random.seed(args.seed)\n",
    "\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset NIID Benchmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from src.client import * \n",
    "from src.utils import *\n",
    "from src.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path\n",
    "# import os\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'cifar100'\n",
    "args.partition='noniid-#label20'\n",
    "args.num_users=100\n",
    "\n",
    "args.rounds=100\n",
    "args.frac = 0.1\n",
    "args.local_bs = 10\n",
    "args.local_ep = 10\n",
    "args.lr = 0.01\n",
    "args.momentum = 0.9\n",
    "\n",
    "args.bias=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "len train_ds_global: 50000\n",
      "len test_ds_global: 10000\n"
     ]
    }
   ],
   "source": [
    "train_dl_global, test_dl_global, train_ds_global, test_ds_global = get_dataloader(args.dataset,\n",
    "                                                                                   args.datadir,\n",
    "                                                                                   args.batch_size,\n",
    "                                                                                   32)\n",
    "\n",
    "print(\"len train_ds_global:\", len(train_ds_global))\n",
    "print(\"len test_ds_global:\", len(test_ds_global))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conv_output_size(Lin,kernel_size,stride=1,padding=0,dilation=1):\n",
    "    return int(np.floor((Lin+2*padding-dilation*(kernel_size-1)-1)/float(stride)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim=10, bias=True):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.bias=bias\n",
    "        self.act=OrderedDict()\n",
    "        self.input_size =[]\n",
    "        self.ksize=[]\n",
    "        self.in_channel =[]\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5, bias=self.bias)\n",
    "        self.input_size.append(32)\n",
    "        self.ksize.append(5)\n",
    "        self.in_channel.append(3)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        s=compute_conv_output_size(32,5)\n",
    "        s=s//2\n",
    "        \n",
    "        self.input_size.append(s)\n",
    "        self.ksize.append(5)\n",
    "        self.in_channel.append(6)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, bias=self.bias)\n",
    "\n",
    "        # for now, we hard coded this network\n",
    "        # i.e. we fix the number of hidden layers i.e. 2 layers\n",
    "        s=compute_conv_output_size(s,5)\n",
    "        s=s//2\n",
    "        self.input_size.append(s*s*16)\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dims[0], bias=self.bias)\n",
    "        \n",
    "        self.input_size.append(hidden_dims[0])\n",
    "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1], bias=self.bias)\n",
    "        \n",
    "        self.input_size.append(hidden_dims[1])\n",
    "        self.fc3 = nn.Linear(hidden_dims[1], output_dim, bias=self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.act['conv1']=x\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        self.act['conv2']=x\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        self.act['fc1']=x\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        self.act['fc2']=x\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        self.act['fc3']=x\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: resnet9, Dataset: cifar100\n"
     ]
    }
   ],
   "source": [
    "def init_nets(args, dropout_p=0.5, bias=True):\n",
    "\n",
    "    users_model = []\n",
    "\n",
    "    for net_i in range(-1, args.num_users):\n",
    "        if args.dataset == \"generated\":\n",
    "            net = PerceptronModel().to(args.device)\n",
    "        elif args.model == \"mlp\":\n",
    "            if args.dataset == 'covtype':\n",
    "                input_size = 54\n",
    "                output_size = 2\n",
    "                hidden_sizes = [32,16,8]\n",
    "            elif args.dataset == 'a9a':\n",
    "                input_size = 123\n",
    "                output_size = 2\n",
    "                hidden_sizes = [32,16,8]\n",
    "            elif args.dataset == 'rcv1':\n",
    "                input_size = 47236\n",
    "                output_size = 2\n",
    "                hidden_sizes = [32,16,8]\n",
    "            elif args.dataset == 'SUSY':\n",
    "                input_size = 18\n",
    "                output_size = 2\n",
    "                hidden_sizes = [16,8]\n",
    "            net = FcNet(input_size, hidden_sizes, output_size, dropout_p).to(args.device)\n",
    "        elif args.model == \"vgg\":\n",
    "            net = vgg11().to(args.device)\n",
    "        elif args.model == \"simple-cnn\":\n",
    "            if args.dataset in (\"cifar10\", \"cinic10\", \"svhn\"):\n",
    "                net = SimpleCNN(input_dim=(16 * 5 * 5), hidden_dims=[120, 84], output_dim=10, bias=bias).to(args.device)\n",
    "            elif args.dataset in (\"mnist\", 'femnist', 'fmnist'):\n",
    "                net = SimpleCNNMNIST(input_dim=(16 * 4 * 4), hidden_dims=[120, 84], output_dim=10).to(args.device)\n",
    "            elif args.dataset == 'celeba':\n",
    "                net = SimpleCNN(input_dim=(16 * 5 * 5), hidden_dims=[120, 84], output_dim=2).to(args.device)\n",
    "        elif args.model ==\"simple-cnn-3\":\n",
    "            if args.dataset == 'cifar100': \n",
    "                net = SimpleCNN_3(input_dim=(16 * 3 * 5 * 5), hidden_dims=[120*3, 84*3], output_dim=100).to(args.device)\n",
    "            if args.dataset == 'tinyimagenet':\n",
    "                net = SimpleCNNTinyImagenet_3(input_dim=(16 * 3 * 13 * 13), hidden_dims=[120*3, 84*3], \n",
    "                                              output_dim=200).to(args.device)\n",
    "        elif args.model == \"vgg-9\":\n",
    "            if args.dataset in (\"mnist\", 'femnist'):\n",
    "                net = ModerateCNNMNIST().to(args.device)\n",
    "            elif args.dataset in (\"cifar10\", \"cinic10\", \"svhn\"):\n",
    "                # print(\"in moderate cnn\")\n",
    "                net = ModerateCNN().to(args.device)\n",
    "            elif args.dataset == 'celeba':\n",
    "                net = ModerateCNN(output_dim=2).to(args.device)\n",
    "        elif args.model == 'resnet9':\n",
    "            if args.dataset == 'cifar100':\n",
    "                net = ResNet9(in_channels=3, num_classes=100)\n",
    "            elif args.dataset == 'tinyimagenet':\n",
    "                net = ResNet9(in_channels=3, num_classes=200, dim=512*2*2)\n",
    "        elif args.model == \"resnet\":\n",
    "            net = ResNet50_cifar10().to(args.device)\n",
    "        elif args.model == \"vgg16\":\n",
    "            net = vgg16().to(args.device)\n",
    "        else:\n",
    "            print(\"not supported yet\")\n",
    "            exit(1)\n",
    "        if net_i == -1:\n",
    "            net_glob = copy.deepcopy(net)\n",
    "            initial_state_dict = copy.deepcopy(net_glob.state_dict())\n",
    "            server_state_dict = copy.deepcopy(net_glob.state_dict())\n",
    "            if args.load_initial:\n",
    "                initial_state_dict = torch.load(args.load_initial)\n",
    "                server_state_dict = torch.load(args.load_initial)\n",
    "                net_glob.load_state_dict(initial_state_dict)\n",
    "        else:\n",
    "            users_model.append(copy.deepcopy(net))\n",
    "            users_model[net_i].load_state_dict(initial_state_dict)\n",
    "\n",
    "    return users_model, net_glob, initial_state_dict, server_state_dict\n",
    "\n",
    "print(f'MODEL: {args.model}, Dataset: {args.dataset}')\n",
    "\n",
    "# users_model, net_glob, initial_state_dict, server_state_dict = init_nets(args, dropout_p=0.5, bias=args.bias)\n",
    "\n",
    "# print(net_glob)\n",
    "\n",
    "# total = 0 \n",
    "# for name, param in net_glob.named_parameters():\n",
    "#     print(name, param.size())\n",
    "#     total += np.prod(param.size())\n",
    "#     #print(np.array(param.data.cpu().numpy().reshape([-1])))\n",
    "#     #print(isinstance(param.data.cpu().numpy(), np.array))\n",
    "# print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def conv_bn_relu_pool(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        #nn.GroupNorm(32,out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    ]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, dim=512):\n",
    "        super().__init__()\n",
    "        self.prep = conv_bn_relu_pool(in_channels, 64)\n",
    "        self.layer1_head = conv_bn_relu_pool(64, 128, pool=True)\n",
    "        self.layer1_residual = nn.Sequential(conv_bn_relu_pool(128, 128), conv_bn_relu_pool(128, 128))\n",
    "        self.layer2 = conv_bn_relu_pool(128, 256, pool=True)\n",
    "        self.layer3_head = conv_bn_relu_pool(256, 512, pool=True)\n",
    "        self.layer3_residual = nn.Sequential(conv_bn_relu_pool(512, 512), conv_bn_relu_pool(512, 512))\n",
    "        self.MaxPool2d = nn.Sequential(\n",
    "            nn.MaxPool2d(4))\n",
    "        self.linear = nn.Linear(dim, num_classes)\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.MaxPool2d(4),\n",
    "        #     nn.Flatten(),\n",
    "        #     nn.Linear(512, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        x = self.layer1_head(x)\n",
    "        x = self.layer1_residual(x) + x\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3_head(x)\n",
    "        x = self.layer3_residual(x) + x\n",
    "        x = self.MaxPool2d(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clients Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cifar100, noniid-#label20 for all clients\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "K: 100\n",
      "partition: noniid-#label20\n",
      "Data statistics Train:\n",
      " {0: {0: 39, 3: 39, 4: 39, 8: 24, 10: 28, 14: 27, 19: 21, 23: 24, 36: 25, 37: 17, 42: 25, 51: 27, 53: 27, 58: 24, 66: 27, 71: 23, 72: 28, 78: 18, 83: 18, 90: 24}, 1: {1: 34, 5: 24, 6: 23, 7: 27, 9: 32, 18: 23, 20: 23, 36: 25, 38: 39, 39: 27, 40: 23, 44: 25, 45: 22, 46: 22, 50: 20, 53: 27, 62: 23, 80: 34, 84: 25, 86: 21}, 2: {2: 39, 8: 24, 12: 25, 18: 23, 27: 25, 29: 27, 30: 27, 39: 27, 50: 20, 52: 27, 56: 22, 61: 27, 62: 23, 68: 24, 72: 28, 74: 24, 81: 39, 82: 25, 90: 24, 94: 22}, 3: {3: 39, 6: 23, 16: 28, 18: 23, 21: 17, 23: 24, 24: 28, 31: 20, 35: 19, 37: 17, 53: 27, 57: 22, 66: 27, 78: 18, 79: 25, 82: 25, 83: 18, 86: 21, 88: 24, 95: 28}, 4: {4: 39, 9: 32, 12: 25, 13: 20, 19: 21, 30: 27, 32: 22, 33: 22, 35: 19, 37: 17, 47: 23, 49: 27, 60: 27, 62: 23, 71: 23, 73: 32, 82: 25, 85: 25, 87: 32, 91: 25}, 5: {5: 24, 8: 24, 11: 25, 12: 25, 18: 23, 19: 21, 23: 24, 24: 28, 25: 20, 32: 22, 35: 19, 50: 20, 67: 34, 69: 28, 71: 23, 74: 24, 76: 27, 78: 18, 83: 18, 89: 19}, 6: {0: 39, 1: 34, 5: 24, 6: 23, 7: 27, 19: 21, 26: 34, 32: 22, 37: 17, 45: 22, 47: 23, 54: 25, 55: 30, 71: 23, 74: 24, 76: 27, 77: 30, 89: 19, 96: 27, 99: 19}, 7: {7: 27, 8: 24, 11: 25, 14: 27, 20: 23, 21: 17, 25: 20, 26: 34, 37: 17, 38: 39, 49: 27, 57: 22, 58: 24, 80: 34, 82: 25, 86: 21, 90: 24, 92: 27, 96: 27, 98: 25}, 8: {1: 34, 2: 39, 5: 24, 8: 24, 9: 32, 15: 34, 24: 28, 28: 32, 34: 50, 44: 25, 47: 23, 48: 22, 51: 27, 61: 27, 69: 28, 70: 27, 75: 30, 79: 25, 93: 27, 97: 36}, 9: {7: 27, 9: 32, 10: 28, 11: 25, 12: 25, 15: 34, 21: 17, 24: 28, 32: 22, 33: 22, 50: 20, 51: 27, 56: 22, 59: 18, 60: 27, 61: 27, 67: 34, 88: 24, 89: 19, 99: 19}, 10: {3: 39, 4: 39, 5: 24, 10: 28, 15: 34, 32: 22, 33: 22, 35: 19, 39: 27, 50: 20, 62: 23, 65: 28, 68: 24, 70: 27, 79: 25, 86: 21, 88: 24, 92: 27, 93: 27, 94: 22}, 11: {7: 27, 11: 25, 14: 27, 18: 23, 29: 27, 36: 25, 37: 17, 41: 39, 44: 25, 47: 23, 55: 30, 63: 28, 66: 27, 67: 34, 77: 30, 79: 25, 84: 25, 86: 21, 90: 24, 99: 19}, 12: {1: 34, 12: 25, 13: 20, 20: 23, 31: 20, 49: 27, 51: 27, 54: 25, 55: 30, 56: 22, 66: 27, 68: 24, 69: 28, 70: 27, 80: 34, 83: 18, 85: 25, 89: 19, 91: 25, 96: 27}, 13: {2: 39, 13: 20, 14: 27, 16: 28, 18: 23, 19: 21, 23: 24, 32: 22, 35: 19, 36: 25, 38: 39, 39: 27, 40: 23, 42: 25, 54: 25, 60: 27, 81: 39, 86: 21, 88: 24, 93: 27}, 14: {5: 24, 13: 20, 14: 27, 19: 21, 25: 20, 29: 27, 38: 39, 40: 23, 43: 34, 45: 22, 47: 23, 54: 25, 59: 18, 66: 27, 69: 28, 74: 24, 77: 30, 78: 18, 86: 21, 98: 25}, 15: {3: 39, 14: 27, 15: 34, 25: 20, 28: 32, 29: 27, 31: 20, 35: 19, 47: 23, 56: 22, 62: 23, 63: 28, 64: 27, 83: 18, 84: 25, 89: 19, 92: 27, 93: 27, 94: 22, 97: 36}, 16: {11: 25, 16: 28, 20: 23, 21: 17, 24: 28, 26: 34, 27: 25, 30: 27, 31: 20, 41: 39, 54: 25, 55: 30, 64: 27, 66: 27, 79: 25, 80: 34, 82: 25, 85: 25, 93: 27, 96: 27}, 17: {2: 39, 6: 23, 7: 27, 8: 24, 13: 20, 17: 20, 18: 23, 33: 22, 35: 19, 45: 22, 46: 22, 50: 20, 54: 25, 57: 22, 67: 34, 76: 27, 78: 18, 89: 19, 91: 25, 93: 27}, 18: {0: 39, 3: 39, 12: 25, 15: 34, 18: 23, 22: 22, 31: 20, 35: 19, 37: 17, 41: 39, 43: 34, 50: 19, 51: 27, 60: 27, 62: 23, 63: 28, 67: 34, 70: 27, 75: 30, 91: 25}, 19: {1: 34, 10: 28, 16: 28, 19: 21, 21: 16, 22: 22, 33: 22, 36: 25, 39: 27, 40: 23, 41: 39, 44: 25, 56: 22, 60: 27, 66: 26, 68: 24, 70: 27, 87: 32, 92: 27, 93: 26}, 20: {1: 33, 20: 23, 27: 25, 28: 32, 29: 27, 33: 22, 44: 25, 47: 23, 52: 27, 53: 27, 54: 25, 56: 22, 60: 27, 71: 23, 74: 24, 78: 18, 79: 25, 83: 18, 88: 24, 89: 19}, 21: {6: 23, 17: 20, 21: 16, 22: 22, 28: 32, 35: 19, 37: 17, 43: 34, 50: 19, 51: 27, 53: 27, 56: 22, 68: 24, 72: 28, 73: 32, 86: 21, 89: 19, 90: 24, 94: 22, 96: 27}, 22: {5: 24, 8: 24, 11: 25, 17: 20, 20: 23, 22: 22, 27: 25, 29: 27, 33: 22, 35: 19, 40: 23, 45: 22, 48: 22, 49: 27, 50: 19, 57: 22, 61: 27, 69: 28, 93: 26, 96: 27}, 23: {6: 23, 23: 24, 24: 28, 28: 31, 29: 26, 37: 17, 40: 23, 41: 39, 43: 34, 45: 22, 46: 22, 47: 23, 48: 22, 55: 30, 59: 18, 62: 23, 65: 28, 85: 25, 87: 32, 92: 27}, 24: {6: 23, 7: 26, 14: 26, 15: 33, 17: 20, 21: 16, 24: 28, 27: 25, 34: 50, 35: 19, 45: 22, 46: 22, 60: 26, 72: 28, 80: 34, 86: 21, 90: 24, 95: 28, 96: 26, 97: 36}, 25: {10: 28, 11: 25, 21: 16, 25: 20, 28: 31, 36: 25, 40: 23, 47: 23, 48: 22, 55: 30, 63: 28, 65: 28, 76: 27, 78: 18, 81: 39, 83: 18, 85: 25, 86: 21, 88: 24, 99: 19}, 26: {12: 25, 19: 21, 23: 24, 25: 20, 26: 34, 30: 27, 32: 22, 35: 19, 39: 27, 43: 34, 47: 23, 48: 22, 50: 19, 54: 25, 59: 18, 61: 27, 71: 23, 72: 28, 76: 27, 87: 32}, 27: {3: 39, 4: 39, 16: 28, 17: 20, 21: 16, 25: 20, 27: 25, 37: 17, 48: 22, 53: 27, 58: 24, 67: 33, 69: 28, 74: 24, 75: 30, 78: 17, 92: 27, 94: 22, 96: 26, 99: 19}, 28: {2: 39, 6: 23, 10: 28, 18: 23, 28: 31, 31: 20, 43: 33, 46: 22, 54: 25, 60: 26, 61: 27, 63: 28, 68: 24, 73: 32, 74: 24, 86: 21, 90: 24, 97: 36, 98: 25, 99: 19}, 29: {1: 33, 6: 23, 13: 20, 18: 23, 23: 24, 29: 26, 32: 22, 45: 22, 50: 19, 57: 22, 60: 26, 69: 28, 72: 28, 78: 17, 82: 25, 84: 25, 90: 24, 91: 25, 92: 26, 99: 19}, 30: {5: 24, 14: 26, 17: 20, 19: 21, 30: 27, 36: 25, 37: 17, 43: 33, 45: 22, 48: 22, 54: 25, 63: 28, 64: 27, 66: 26, 68: 24, 75: 30, 86: 21, 88: 24, 91: 25, 92: 26}, 31: {0: 39, 1: 33, 9: 31, 11: 25, 12: 25, 16: 28, 20: 23, 31: 19, 36: 25, 37: 17, 44: 25, 45: 22, 46: 22, 48: 22, 57: 22, 59: 18, 71: 23, 73: 32, 88: 24, 91: 25}, 32: {3: 38, 6: 23, 9: 31, 12: 25, 24: 28, 29: 26, 32: 22, 34: 50, 35: 19, 39: 26, 54: 25, 57: 22, 58: 24, 68: 24, 69: 28, 70: 27, 84: 25, 87: 31, 95: 28, 97: 36}, 33: {6: 23, 14: 26, 18: 23, 21: 16, 23: 24, 28: 31, 30: 27, 31: 19, 33: 22, 36: 25, 44: 25, 46: 22, 52: 27, 53: 26, 64: 27, 66: 26, 68: 24, 79: 25, 89: 19, 92: 26}, 34: {4: 39, 19: 21, 22: 22, 31: 19, 33: 22, 34: 50, 41: 39, 42: 25, 43: 33, 46: 22, 54: 25, 55: 30, 64: 27, 79: 25, 80: 33, 85: 25, 87: 31, 93: 26, 95: 28, 96: 26}, 35: {0: 39, 1: 33, 11: 25, 21: 16, 32: 22, 35: 19, 40: 23, 44: 25, 46: 22, 56: 22, 57: 22, 63: 28, 71: 23, 73: 31, 78: 17, 84: 25, 86: 21, 89: 19, 94: 22, 95: 28}, 36: {0: 39, 2: 39, 12: 25, 14: 26, 23: 24, 32: 22, 36: 25, 42: 25, 43: 33, 45: 22, 46: 22, 50: 19, 56: 22, 58: 24, 61: 26, 62: 23, 76: 27, 77: 30, 85: 25, 99: 19}, 37: {9: 31, 10: 28, 13: 19, 21: 16, 25: 20, 37: 17, 38: 39, 42: 25, 44: 25, 62: 23, 65: 28, 71: 23, 79: 25, 84: 25, 87: 31, 89: 19, 91: 25, 92: 26, 95: 28, 99: 19}, 38: {7: 26, 12: 25, 13: 19, 17: 19, 21: 16, 26: 34, 31: 19, 36: 25, 37: 17, 38: 39, 60: 26, 66: 26, 71: 23, 76: 26, 80: 33, 81: 39, 83: 17, 94: 22, 98: 25, 99: 19}, 39: {7: 26, 8: 24, 9: 31, 15: 33, 25: 20, 35: 18, 37: 17, 39: 26, 40: 23, 45: 22, 48: 22, 50: 19, 61: 26, 62: 23, 70: 26, 78: 17, 84: 25, 89: 19, 96: 26, 99: 19}, 40: {5: 24, 6: 23, 13: 19, 19: 21, 21: 16, 26: 33, 29: 26, 37: 17, 40: 23, 49: 27, 50: 19, 53: 26, 61: 26, 62: 23, 73: 31, 74: 24, 79: 25, 81: 39, 87: 31, 94: 22}, 41: {4: 39, 6: 23, 9: 31, 13: 19, 22: 22, 41: 38, 42: 25, 48: 22, 57: 22, 58: 24, 59: 18, 60: 26, 66: 26, 69: 28, 74: 24, 75: 30, 91: 25, 95: 28, 97: 36, 98: 25}, 42: {3: 38, 4: 38, 5: 24, 7: 26, 10: 28, 15: 33, 16: 28, 22: 22, 25: 20, 33: 22, 42: 25, 52: 27, 57: 22, 68: 24, 78: 17, 82: 25, 87: 31, 90: 24, 96: 26, 99: 19}, 43: {3: 38, 16: 28, 28: 31, 35: 18, 36: 25, 40: 23, 43: 33, 46: 22, 50: 19, 51: 26, 68: 24, 71: 23, 72: 28, 73: 31, 76: 26, 77: 30, 79: 25, 80: 33, 82: 25, 92: 26}, 44: {8: 24, 9: 31, 12: 25, 21: 16, 22: 22, 25: 20, 28: 31, 31: 19, 37: 17, 44: 25, 50: 19, 52: 27, 54: 25, 55: 29, 56: 22, 62: 23, 68: 24, 69: 28, 70: 26, 79: 25}, 45: {8: 24, 9: 31, 16: 28, 18: 23, 28: 31, 39: 26, 44: 25, 45: 22, 46: 22, 48: 22, 56: 22, 58: 24, 59: 18, 61: 26, 67: 33, 68: 24, 69: 28, 81: 39, 87: 31, 89: 19}, 46: {7: 26, 11: 25, 20: 23, 22: 22, 24: 28, 25: 20, 27: 25, 29: 26, 32: 22, 36: 25, 37: 17, 39: 26, 43: 33, 46: 22, 47: 23, 61: 26, 67: 33, 94: 22, 96: 26, 99: 19}, 47: {10: 28, 11: 25, 13: 19, 23: 24, 26: 33, 29: 26, 30: 26, 42: 25, 47: 23, 51: 26, 52: 27, 53: 26, 57: 22, 76: 26, 77: 30, 86: 21, 89: 19, 90: 24, 94: 22, 99: 19}, 48: {10: 28, 14: 26, 18: 23, 23: 24, 30: 26, 35: 18, 37: 17, 38: 38, 39: 26, 48: 22, 49: 27, 51: 26, 55: 29, 58: 24, 59: 18, 64: 27, 65: 28, 86: 21, 90: 24, 95: 28}, 49: {6: 23, 10: 28, 17: 19, 22: 22, 26: 33, 27: 25, 47: 23, 49: 26, 52: 26, 56: 22, 59: 18, 63: 28, 72: 28, 78: 17, 83: 17, 88: 24, 91: 25, 92: 26, 95: 28, 98: 25}, 50: {7: 26, 16: 28, 20: 23, 21: 16, 25: 20, 26: 33, 29: 26, 32: 22, 48: 22, 50: 19, 58: 24, 59: 18, 76: 26, 79: 25, 86: 21, 87: 31, 88: 24, 93: 26, 94: 22, 96: 26}, 51: {7: 26, 14: 26, 22: 22, 27: 25, 40: 23, 41: 38, 49: 26, 50: 19, 51: 26, 52: 26, 58: 24, 62: 23, 67: 33, 76: 26, 79: 25, 82: 25, 83: 17, 85: 25, 89: 18, 91: 25}, 52: {17: 19, 19: 21, 22: 22, 27: 25, 38: 38, 40: 23, 44: 25, 48: 22, 51: 26, 52: 26, 54: 25, 60: 26, 62: 23, 65: 28, 76: 26, 78: 17, 82: 25, 84: 25, 94: 22, 96: 26}, 53: {11: 25, 13: 19, 17: 19, 24: 28, 26: 33, 31: 19, 32: 22, 40: 23, 43: 33, 53: 26, 59: 18, 66: 26, 73: 31, 74: 24, 75: 30, 77: 30, 80: 33, 84: 25, 85: 25, 99: 18}, 54: {20: 23, 24: 28, 27: 25, 29: 26, 30: 26, 31: 19, 40: 23, 45: 22, 46: 22, 47: 23, 52: 26, 54: 25, 55: 29, 64: 26, 74: 24, 75: 30, 83: 17, 85: 25, 92: 26, 95: 28}, 55: {3: 38, 18: 23, 19: 21, 25: 20, 27: 25, 38: 38, 44: 25, 47: 23, 54: 25, 55: 29, 58: 24, 60: 26, 63: 28, 70: 26, 80: 33, 81: 38, 86: 21, 87: 31, 92: 26, 98: 25}, 56: {2: 38, 5: 24, 6: 23, 17: 19, 20: 23, 22: 22, 30: 26, 33: 22, 34: 50, 41: 38, 44: 25, 52: 26, 56: 22, 59: 18, 68: 24, 77: 29, 79: 25, 83: 17, 90: 24, 98: 25}, 57: {9: 31, 17: 19, 22: 22, 23: 24, 35: 18, 39: 26, 42: 25, 45: 22, 46: 22, 48: 22, 50: 19, 51: 26, 52: 26, 57: 22, 59: 18, 64: 26, 74: 24, 76: 26, 98: 25, 99: 18}, 58: {5: 24, 11: 25, 12: 25, 16: 28, 19: 21, 20: 23, 31: 19, 32: 22, 42: 25, 48: 22, 49: 26, 51: 26, 53: 26, 58: 24, 65: 28, 70: 26, 71: 23, 74: 24, 77: 29, 79: 25}, 59: {0: 38, 8: 24, 20: 23, 21: 16, 30: 26, 31: 19, 35: 18, 36: 25, 39: 26, 49: 26, 54: 25, 58: 24, 59: 18, 63: 28, 67: 33, 70: 26, 83: 17, 88: 24, 95: 28, 99: 18}, 60: {8: 24, 14: 26, 19: 21, 21: 16, 24: 28, 31: 19, 33: 22, 39: 26, 44: 25, 50: 19, 54: 25, 60: 26, 62: 23, 63: 28, 65: 28, 73: 31, 74: 24, 78: 17, 83: 17, 96: 26}, 61: {7: 26, 16: 28, 17: 19, 18: 23, 22: 22, 25: 20, 26: 33, 32: 22, 39: 26, 46: 22, 47: 23, 57: 22, 60: 26, 61: 26, 66: 26, 70: 26, 71: 23, 78: 17, 90: 24, 99: 18}, 62: {2: 38, 8: 24, 14: 26, 15: 33, 21: 16, 22: 22, 23: 24, 34: 50, 37: 17, 45: 22, 46: 22, 49: 26, 52: 26, 55: 29, 57: 22, 62: 23, 70: 26, 74: 24, 91: 25, 98: 25}, 63: {1: 33, 5: 24, 6: 23, 13: 19, 21: 16, 25: 20, 31: 19, 53: 26, 57: 22, 62: 22, 63: 28, 65: 28, 70: 26, 72: 28, 77: 29, 78: 17, 82: 25, 86: 21, 88: 24, 98: 25}, 64: {4: 38, 13: 19, 18: 23, 25: 20, 27: 25, 34: 50, 45: 22, 47: 22, 55: 29, 58: 24, 59: 18, 64: 26, 67: 33, 75: 29, 76: 26, 82: 25, 86: 21, 94: 22, 95: 28, 97: 36}, 65: {4: 38, 14: 26, 15: 33, 17: 19, 18: 22, 19: 21, 25: 20, 35: 18, 40: 23, 53: 26, 54: 25, 57: 22, 60: 26, 65: 28, 75: 29, 82: 25, 83: 17, 92: 26, 94: 22, 97: 36}, 66: {2: 38, 4: 38, 5: 24, 9: 31, 11: 25, 17: 19, 19: 21, 21: 16, 25: 20, 27: 25, 38: 38, 42: 25, 45: 21, 58: 24, 64: 26, 66: 26, 77: 29, 78: 17, 85: 25, 94: 22}, 67: {5: 24, 13: 19, 18: 22, 21: 16, 23: 24, 30: 26, 33: 22, 36: 25, 37: 16, 52: 26, 59: 18, 60: 26, 61: 26, 64: 26, 66: 26, 67: 33, 80: 33, 88: 24, 90: 24, 99: 18}, 68: {8: 24, 17: 19, 22: 22, 26: 33, 27: 25, 43: 33, 46: 21, 50: 19, 57: 22, 62: 22, 65: 28, 68: 24, 71: 23, 74: 24, 83: 17, 84: 25, 89: 18, 90: 24, 91: 25, 98: 25}, 69: {13: 19, 30: 26, 33: 22, 36: 25, 37: 16, 40: 22, 45: 21, 46: 21, 49: 26, 52: 26, 59: 18, 66: 26, 67: 33, 68: 24, 69: 28, 71: 23, 78: 17, 82: 25, 95: 28, 96: 26}, 70: {0: 38, 12: 25, 13: 19, 14: 26, 22: 21, 23: 24, 43: 33, 45: 21, 46: 21, 47: 22, 53: 26, 56: 22, 70: 26, 71: 23, 76: 26, 86: 21, 88: 24, 89: 18, 93: 26, 98: 25}, 71: {0: 38, 5: 24, 13: 19, 14: 26, 18: 22, 21: 16, 30: 26, 31: 19, 32: 22, 35: 18, 37: 16, 55: 29, 56: 22, 59: 18, 71: 22, 74: 24, 75: 29, 78: 17, 85: 25, 91: 25}, 72: {2: 38, 3: 38, 5: 24, 13: 19, 15: 33, 17: 19, 22: 21, 23: 24, 29: 26, 36: 25, 48: 22, 52: 26, 56: 22, 59: 18, 60: 26, 63: 28, 72: 28, 83: 17, 89: 18, 90: 24}, 73: {16: 28, 18: 22, 20: 23, 21: 16, 27: 25, 30: 26, 42: 25, 49: 26, 53: 26, 54: 25, 58: 24, 67: 33, 68: 24, 70: 26, 72: 28, 73: 31, 80: 33, 85: 25, 90: 24, 93: 26}, 74: {0: 38, 8: 24, 9: 31, 10: 28, 11: 25, 12: 25, 13: 19, 20: 23, 21: 16, 23: 24, 24: 28, 25: 20, 50: 19, 56: 22, 65: 28, 71: 22, 74: 23, 84: 25, 85: 25, 95: 28}, 75: {0: 38, 6: 22, 7: 26, 12: 25, 17: 19, 31: 19, 38: 38, 45: 21, 48: 21, 51: 26, 59: 18, 68: 23, 70: 26, 71: 22, 72: 28, 75: 29, 78: 17, 84: 25, 94: 22, 98: 25}, 76: {1: 33, 5: 23, 12: 25, 14: 26, 37: 16, 42: 25, 43: 33, 46: 21, 49: 26, 55: 29, 57: 21, 58: 24, 62: 22, 65: 28, 68: 23, 76: 26, 78: 17, 83: 17, 98: 25, 99: 18}, 77: {1: 33, 11: 25, 13: 19, 20: 23, 22: 21, 23: 23, 28: 31, 31: 19, 40: 22, 42: 25, 50: 19, 56: 21, 58: 23, 59: 18, 64: 26, 65: 28, 76: 26, 77: 29, 83: 17, 89: 18}, 78: {1: 33, 8: 24, 24: 28, 26: 33, 27: 25, 28: 31, 31: 19, 34: 50, 35: 18, 42: 25, 46: 21, 51: 26, 59: 18, 64: 26, 70: 26, 72: 28, 78: 17, 82: 25, 83: 17, 86: 20}, 79: {0: 38, 18: 22, 19: 21, 21: 16, 28: 31, 33: 22, 40: 22, 42: 25, 57: 21, 58: 23, 61: 26, 79: 25, 81: 38, 83: 17, 90: 23, 91: 25, 93: 26, 94: 22, 97: 36, 99: 18}, 80: {5: 23, 9: 31, 12: 25, 13: 19, 18: 22, 25: 20, 35: 18, 37: 16, 39: 26, 47: 22, 49: 26, 50: 19, 55: 29, 72: 28, 75: 29, 80: 33, 84: 25, 85: 25, 88: 24, 93: 26}, 81: {7: 26, 11: 25, 12: 25, 13: 19, 16: 28, 17: 19, 20: 22, 25: 20, 32: 21, 48: 21, 53: 26, 59: 18, 62: 22, 71: 22, 72: 27, 76: 26, 81: 38, 87: 31, 94: 21, 96: 26}, 82: {1: 33, 2: 38, 4: 38, 7: 26, 8: 24, 17: 19, 19: 21, 25: 20, 33: 22, 41: 38, 50: 19, 59: 18, 68: 23, 78: 17, 82: 25, 84: 25, 85: 25, 91: 25, 98: 25, 99: 18}, 83: {6: 22, 13: 19, 16: 27, 21: 16, 22: 21, 30: 26, 32: 21, 33: 22, 41: 38, 42: 25, 59: 17, 64: 26, 65: 27, 70: 26, 75: 29, 78: 17, 83: 17, 85: 25, 89: 18, 94: 21}, 84: {6: 22, 14: 26, 16: 27, 19: 21, 21: 16, 24: 27, 25: 20, 26: 33, 31: 19, 37: 16, 45: 21, 56: 21, 69: 28, 72: 27, 75: 29, 77: 29, 84: 25, 85: 25, 93: 26, 94: 21}, 85: {10: 28, 11: 25, 13: 19, 16: 27, 30: 26, 31: 19, 32: 21, 33: 21, 34: 50, 36: 25, 37: 16, 44: 25, 49: 26, 64: 26, 66: 26, 81: 38, 85: 25, 91: 25, 93: 26, 97: 36}, 86: {11: 25, 23: 23, 35: 18, 37: 16, 40: 22, 48: 21, 51: 26, 58: 23, 63: 28, 69: 28, 73: 31, 83: 17, 84: 25, 86: 20, 88: 24, 89: 18, 95: 27, 97: 35, 98: 25, 99: 18}, 87: {10: 28, 20: 22, 21: 16, 24: 27, 25: 20, 29: 26, 33: 21, 35: 18, 52: 26, 55: 29, 61: 26, 63: 27, 67: 33, 72: 27, 77: 29, 82: 25, 83: 17, 87: 31, 90: 23, 93: 26}, 88: {2: 38, 8: 23, 10: 27, 20: 22, 27: 25, 29: 26, 36: 25, 37: 16, 39: 26, 49: 26, 53: 26, 57: 21, 62: 22, 63: 27, 64: 26, 65: 27, 71: 22, 73: 31, 78: 17, 88: 24}, 89: {1: 33, 3: 38, 10: 27, 15: 33, 17: 19, 20: 22, 28: 31, 32: 21, 33: 21, 36: 25, 50: 19, 53: 26, 56: 21, 74: 23, 77: 29, 81: 38, 83: 17, 88: 23, 89: 18, 97: 35}, 90: {2: 38, 6: 22, 9: 31, 10: 27, 15: 33, 19: 20, 20: 22, 26: 33, 31: 19, 37: 16, 40: 22, 44: 25, 49: 26, 61: 26, 72: 27, 78: 17, 79: 25, 90: 23, 92: 26, 96: 26}, 91: {4: 38, 6: 22, 19: 20, 22: 21, 27: 25, 32: 21, 33: 21, 35: 18, 42: 25, 48: 21, 60: 26, 61: 26, 75: 29, 82: 25, 83: 17, 86: 20, 88: 23, 89: 18, 91: 25, 99: 18}, 92: {5: 23, 10: 27, 17: 19, 21: 16, 32: 21, 44: 25, 46: 21, 51: 26, 52: 26, 61: 26, 62: 22, 63: 27, 66: 26, 68: 23, 71: 22, 75: 29, 77: 29, 80: 33, 86: 20, 92: 26}, 93: {7: 26, 8: 23, 13: 19, 30: 26, 38: 38, 47: 22, 53: 26, 56: 21, 57: 21, 58: 23, 63: 27, 65: 27, 69: 27, 73: 31, 74: 23, 77: 29, 84: 25, 93: 26, 97: 35, 98: 25}, 94: {4: 38, 6: 22, 8: 23, 12: 25, 15: 33, 23: 23, 24: 27, 33: 21, 39: 26, 45: 21, 57: 21, 64: 26, 78: 17, 79: 25, 81: 38, 84: 25, 88: 23, 92: 26, 94: 21, 98: 25}, 95: {17: 19, 21: 16, 22: 21, 35: 18, 42: 25, 47: 22, 51: 26, 61: 26, 69: 27, 73: 31, 75: 29, 76: 26, 82: 25, 83: 17, 85: 25, 87: 31, 89: 18, 94: 21, 95: 27, 99: 18}, 96: {5: 23, 11: 25, 15: 33, 17: 19, 23: 23, 29: 26, 30: 26, 33: 21, 34: 50, 38: 38, 40: 22, 41: 38, 51: 26, 59: 17, 64: 26, 83: 17, 89: 18, 92: 26, 93: 26, 96: 26}, 97: {3: 38, 16: 27, 17: 19, 19: 20, 20: 22, 31: 19, 42: 25, 44: 25, 47: 22, 56: 21, 59: 17, 66: 26, 79: 25, 81: 38, 82: 25, 83: 17, 89: 18, 95: 27, 97: 35, 99: 18}, 98: {7: 26, 17: 19, 27: 25, 28: 31, 29: 26, 41: 38, 48: 21, 56: 21, 64: 26, 69: 27, 73: 31, 74: 23, 78: 17, 80: 33, 84: 25, 87: 31, 89: 18, 90: 23, 91: 25, 98: 25}, 99: {0: 38, 8: 23, 19: 20, 24: 27, 31: 19, 39: 26, 44: 25, 48: 21, 49: 26, 52: 26, 57: 21, 59: 17, 65: 27, 69: 27, 73: 31, 88: 23, 91: 25, 94: 21, 95: 27, 99: 18}} \n",
      "\n",
      "Data statistics Test:\n",
      " {0: {0: 100, 3: 100, 4: 100, 8: 100, 10: 100, 14: 100, 19: 100, 23: 100, 36: 100, 37: 100, 42: 100, 51: 100, 53: 100, 58: 100, 66: 100, 71: 100, 72: 100, 78: 100, 83: 100, 90: 100}, 1: {1: 100, 5: 100, 6: 100, 7: 100, 9: 100, 18: 100, 20: 100, 36: 100, 38: 100, 39: 100, 40: 100, 44: 100, 45: 100, 46: 100, 50: 100, 53: 100, 62: 100, 80: 100, 84: 100, 86: 100}, 2: {2: 100, 8: 100, 12: 100, 18: 100, 27: 100, 29: 100, 30: 100, 39: 100, 50: 100, 52: 100, 56: 100, 61: 100, 62: 100, 68: 100, 72: 100, 74: 100, 81: 100, 82: 100, 90: 100, 94: 100}, 3: {3: 100, 6: 100, 16: 100, 18: 100, 21: 100, 23: 100, 24: 100, 31: 100, 35: 100, 37: 100, 53: 100, 57: 100, 66: 100, 78: 100, 79: 100, 82: 100, 83: 100, 86: 100, 88: 100, 95: 100}, 4: {4: 100, 9: 100, 12: 100, 13: 100, 19: 100, 30: 100, 32: 100, 33: 100, 35: 100, 37: 100, 47: 100, 49: 100, 60: 100, 62: 100, 71: 100, 73: 100, 82: 100, 85: 100, 87: 100, 91: 100}, 5: {5: 100, 8: 100, 11: 100, 12: 100, 18: 100, 19: 100, 23: 100, 24: 100, 25: 100, 32: 100, 35: 100, 50: 100, 67: 100, 69: 100, 71: 100, 74: 100, 76: 100, 78: 100, 83: 100, 89: 100}, 6: {0: 100, 1: 100, 5: 100, 6: 100, 7: 100, 19: 100, 26: 100, 32: 100, 37: 100, 45: 100, 47: 100, 54: 100, 55: 100, 71: 100, 74: 100, 76: 100, 77: 100, 89: 100, 96: 100, 99: 100}, 7: {7: 100, 8: 100, 11: 100, 14: 100, 20: 100, 21: 100, 25: 100, 26: 100, 37: 100, 38: 100, 49: 100, 57: 100, 58: 100, 80: 100, 82: 100, 86: 100, 90: 100, 92: 100, 96: 100, 98: 100}, 8: {1: 100, 2: 100, 5: 100, 8: 100, 9: 100, 15: 100, 24: 100, 28: 100, 34: 100, 44: 100, 47: 100, 48: 100, 51: 100, 61: 100, 69: 100, 70: 100, 75: 100, 79: 100, 93: 100, 97: 100}, 9: {7: 100, 9: 100, 10: 100, 11: 100, 12: 100, 15: 100, 21: 100, 24: 100, 32: 100, 33: 100, 50: 100, 51: 100, 56: 100, 59: 100, 60: 100, 61: 100, 67: 100, 88: 100, 89: 100, 99: 100}, 10: {3: 100, 4: 100, 5: 100, 10: 100, 15: 100, 32: 100, 33: 100, 35: 100, 39: 100, 50: 100, 62: 100, 65: 100, 68: 100, 70: 100, 79: 100, 86: 100, 88: 100, 92: 100, 93: 100, 94: 100}, 11: {7: 100, 11: 100, 14: 100, 18: 100, 29: 100, 36: 100, 37: 100, 41: 100, 44: 100, 47: 100, 55: 100, 63: 100, 66: 100, 67: 100, 77: 100, 79: 100, 84: 100, 86: 100, 90: 100, 99: 100}, 12: {1: 100, 12: 100, 13: 100, 20: 100, 31: 100, 49: 100, 51: 100, 54: 100, 55: 100, 56: 100, 66: 100, 68: 100, 69: 100, 70: 100, 80: 100, 83: 100, 85: 100, 89: 100, 91: 100, 96: 100}, 13: {2: 100, 13: 100, 14: 100, 16: 100, 18: 100, 19: 100, 23: 100, 32: 100, 35: 100, 36: 100, 38: 100, 39: 100, 40: 100, 42: 100, 54: 100, 60: 100, 81: 100, 86: 100, 88: 100, 93: 100}, 14: {5: 100, 13: 100, 14: 100, 19: 100, 25: 100, 29: 100, 38: 100, 40: 100, 43: 100, 45: 100, 47: 100, 54: 100, 59: 100, 66: 100, 69: 100, 74: 100, 77: 100, 78: 100, 86: 100, 98: 100}, 15: {3: 100, 14: 100, 15: 100, 25: 100, 28: 100, 29: 100, 31: 100, 35: 100, 47: 100, 56: 100, 62: 100, 63: 100, 64: 100, 83: 100, 84: 100, 89: 100, 92: 100, 93: 100, 94: 100, 97: 100}, 16: {11: 100, 16: 100, 20: 100, 21: 100, 24: 100, 26: 100, 27: 100, 30: 100, 31: 100, 41: 100, 54: 100, 55: 100, 64: 100, 66: 100, 79: 100, 80: 100, 82: 100, 85: 100, 93: 100, 96: 100}, 17: {2: 100, 6: 100, 7: 100, 8: 100, 13: 100, 17: 100, 18: 100, 33: 100, 35: 100, 45: 100, 46: 100, 50: 100, 54: 100, 57: 100, 67: 100, 76: 100, 78: 100, 89: 100, 91: 100, 93: 100}, 18: {0: 100, 3: 100, 12: 100, 15: 100, 18: 100, 22: 100, 31: 100, 35: 100, 37: 100, 41: 100, 43: 100, 50: 100, 51: 100, 60: 100, 62: 100, 63: 100, 67: 100, 70: 100, 75: 100, 91: 100}, 19: {1: 100, 10: 100, 16: 100, 19: 100, 21: 100, 22: 100, 33: 100, 36: 100, 39: 100, 40: 100, 41: 100, 44: 100, 56: 100, 60: 100, 66: 100, 68: 100, 70: 100, 87: 100, 92: 100, 93: 100}, 20: {1: 100, 20: 100, 27: 100, 28: 100, 29: 100, 33: 100, 44: 100, 47: 100, 52: 100, 53: 100, 54: 100, 56: 100, 60: 100, 71: 100, 74: 100, 78: 100, 79: 100, 83: 100, 88: 100, 89: 100}, 21: {6: 100, 17: 100, 21: 100, 22: 100, 28: 100, 35: 100, 37: 100, 43: 100, 50: 100, 51: 100, 53: 100, 56: 100, 68: 100, 72: 100, 73: 100, 86: 100, 89: 100, 90: 100, 94: 100, 96: 100}, 22: {5: 100, 8: 100, 11: 100, 17: 100, 20: 100, 22: 100, 27: 100, 29: 100, 33: 100, 35: 100, 40: 100, 45: 100, 48: 100, 49: 100, 50: 100, 57: 100, 61: 100, 69: 100, 93: 100, 96: 100}, 23: {6: 100, 23: 100, 24: 100, 28: 100, 29: 100, 37: 100, 40: 100, 41: 100, 43: 100, 45: 100, 46: 100, 47: 100, 48: 100, 55: 100, 59: 100, 62: 100, 65: 100, 85: 100, 87: 100, 92: 100}, 24: {6: 100, 7: 100, 14: 100, 15: 100, 17: 100, 21: 100, 24: 100, 27: 100, 34: 100, 35: 100, 45: 100, 46: 100, 60: 100, 72: 100, 80: 100, 86: 100, 90: 100, 95: 100, 96: 100, 97: 100}, 25: {10: 100, 11: 100, 21: 100, 25: 100, 28: 100, 36: 100, 40: 100, 47: 100, 48: 100, 55: 100, 63: 100, 65: 100, 76: 100, 78: 100, 81: 100, 83: 100, 85: 100, 86: 100, 88: 100, 99: 100}, 26: {12: 100, 19: 100, 23: 100, 25: 100, 26: 100, 30: 100, 32: 100, 35: 100, 39: 100, 43: 100, 47: 100, 48: 100, 50: 100, 54: 100, 59: 100, 61: 100, 71: 100, 72: 100, 76: 100, 87: 100}, 27: {3: 100, 4: 100, 16: 100, 17: 100, 21: 100, 25: 100, 27: 100, 37: 100, 48: 100, 53: 100, 58: 100, 67: 100, 69: 100, 74: 100, 75: 100, 78: 100, 92: 100, 94: 100, 96: 100, 99: 100}, 28: {2: 100, 6: 100, 10: 100, 18: 100, 28: 100, 31: 100, 43: 100, 46: 100, 54: 100, 60: 100, 61: 100, 63: 100, 68: 100, 73: 100, 74: 100, 86: 100, 90: 100, 97: 100, 98: 100, 99: 100}, 29: {1: 100, 6: 100, 13: 100, 18: 100, 23: 100, 29: 100, 32: 100, 45: 100, 50: 100, 57: 100, 60: 100, 69: 100, 72: 100, 78: 100, 82: 100, 84: 100, 90: 100, 91: 100, 92: 100, 99: 100}, 30: {5: 100, 14: 100, 17: 100, 19: 100, 30: 100, 36: 100, 37: 100, 43: 100, 45: 100, 48: 100, 54: 100, 63: 100, 64: 100, 66: 100, 68: 100, 75: 100, 86: 100, 88: 100, 91: 100, 92: 100}, 31: {0: 100, 1: 100, 9: 100, 11: 100, 12: 100, 16: 100, 20: 100, 31: 100, 36: 100, 37: 100, 44: 100, 45: 100, 46: 100, 48: 100, 57: 100, 59: 100, 71: 100, 73: 100, 88: 100, 91: 100}, 32: {3: 100, 6: 100, 9: 100, 12: 100, 24: 100, 29: 100, 32: 100, 34: 100, 35: 100, 39: 100, 54: 100, 57: 100, 58: 100, 68: 100, 69: 100, 70: 100, 84: 100, 87: 100, 95: 100, 97: 100}, 33: {6: 100, 14: 100, 18: 100, 21: 100, 23: 100, 28: 100, 30: 100, 31: 100, 33: 100, 36: 100, 44: 100, 46: 100, 52: 100, 53: 100, 64: 100, 66: 100, 68: 100, 79: 100, 89: 100, 92: 100}, 34: {4: 100, 19: 100, 22: 100, 31: 100, 33: 100, 34: 100, 41: 100, 42: 100, 43: 100, 46: 100, 54: 100, 55: 100, 64: 100, 79: 100, 80: 100, 85: 100, 87: 100, 93: 100, 95: 100, 96: 100}, 35: {0: 100, 1: 100, 11: 100, 21: 100, 32: 100, 35: 100, 40: 100, 44: 100, 46: 100, 56: 100, 57: 100, 63: 100, 71: 100, 73: 100, 78: 100, 84: 100, 86: 100, 89: 100, 94: 100, 95: 100}, 36: {0: 100, 2: 100, 12: 100, 14: 100, 23: 100, 32: 100, 36: 100, 42: 100, 43: 100, 45: 100, 46: 100, 50: 100, 56: 100, 58: 100, 61: 100, 62: 100, 76: 100, 77: 100, 85: 100, 99: 100}, 37: {9: 100, 10: 100, 13: 100, 21: 100, 25: 100, 37: 100, 38: 100, 42: 100, 44: 100, 62: 100, 65: 100, 71: 100, 79: 100, 84: 100, 87: 100, 89: 100, 91: 100, 92: 100, 95: 100, 99: 100}, 38: {7: 100, 12: 100, 13: 100, 17: 100, 21: 100, 26: 100, 31: 100, 36: 100, 37: 100, 38: 100, 60: 100, 66: 100, 71: 100, 76: 100, 80: 100, 81: 100, 83: 100, 94: 100, 98: 100, 99: 100}, 39: {7: 100, 8: 100, 9: 100, 15: 100, 25: 100, 35: 100, 37: 100, 39: 100, 40: 100, 45: 100, 48: 100, 50: 100, 61: 100, 62: 100, 70: 100, 78: 100, 84: 100, 89: 100, 96: 100, 99: 100}, 40: {5: 100, 6: 100, 13: 100, 19: 100, 21: 100, 26: 100, 29: 100, 37: 100, 40: 100, 49: 100, 50: 100, 53: 100, 61: 100, 62: 100, 73: 100, 74: 100, 79: 100, 81: 100, 87: 100, 94: 100}, 41: {4: 100, 6: 100, 9: 100, 13: 100, 22: 100, 41: 100, 42: 100, 48: 100, 57: 100, 58: 100, 59: 100, 60: 100, 66: 100, 69: 100, 74: 100, 75: 100, 91: 100, 95: 100, 97: 100, 98: 100}, 42: {3: 100, 4: 100, 5: 100, 7: 100, 10: 100, 15: 100, 16: 100, 22: 100, 25: 100, 33: 100, 42: 100, 52: 100, 57: 100, 68: 100, 78: 100, 82: 100, 87: 100, 90: 100, 96: 100, 99: 100}, 43: {3: 100, 16: 100, 28: 100, 35: 100, 36: 100, 40: 100, 43: 100, 46: 100, 50: 100, 51: 100, 68: 100, 71: 100, 72: 100, 73: 100, 76: 100, 77: 100, 79: 100, 80: 100, 82: 100, 92: 100}, 44: {8: 100, 9: 100, 12: 100, 21: 100, 22: 100, 25: 100, 28: 100, 31: 100, 37: 100, 44: 100, 50: 100, 52: 100, 54: 100, 55: 100, 56: 100, 62: 100, 68: 100, 69: 100, 70: 100, 79: 100}, 45: {8: 100, 9: 100, 16: 100, 18: 100, 28: 100, 39: 100, 44: 100, 45: 100, 46: 100, 48: 100, 56: 100, 58: 100, 59: 100, 61: 100, 67: 100, 68: 100, 69: 100, 81: 100, 87: 100, 89: 100}, 46: {7: 100, 11: 100, 20: 100, 22: 100, 24: 100, 25: 100, 27: 100, 29: 100, 32: 100, 36: 100, 37: 100, 39: 100, 43: 100, 46: 100, 47: 100, 61: 100, 67: 100, 94: 100, 96: 100, 99: 100}, 47: {10: 100, 11: 100, 13: 100, 23: 100, 26: 100, 29: 100, 30: 100, 42: 100, 47: 100, 51: 100, 52: 100, 53: 100, 57: 100, 76: 100, 77: 100, 86: 100, 89: 100, 90: 100, 94: 100, 99: 100}, 48: {10: 100, 14: 100, 18: 100, 23: 100, 30: 100, 35: 100, 37: 100, 38: 100, 39: 100, 48: 100, 49: 100, 51: 100, 55: 100, 58: 100, 59: 100, 64: 100, 65: 100, 86: 100, 90: 100, 95: 100}, 49: {6: 100, 10: 100, 17: 100, 22: 100, 26: 100, 27: 100, 47: 100, 49: 100, 52: 100, 56: 100, 59: 100, 63: 100, 72: 100, 78: 100, 83: 100, 88: 100, 91: 100, 92: 100, 95: 100, 98: 100}, 50: {7: 100, 16: 100, 20: 100, 21: 100, 25: 100, 26: 100, 29: 100, 32: 100, 48: 100, 50: 100, 58: 100, 59: 100, 76: 100, 79: 100, 86: 100, 87: 100, 88: 100, 93: 100, 94: 100, 96: 100}, 51: {7: 100, 14: 100, 22: 100, 27: 100, 40: 100, 41: 100, 49: 100, 50: 100, 51: 100, 52: 100, 58: 100, 62: 100, 67: 100, 76: 100, 79: 100, 82: 100, 83: 100, 85: 100, 89: 100, 91: 100}, 52: {17: 100, 19: 100, 22: 100, 27: 100, 38: 100, 40: 100, 44: 100, 48: 100, 51: 100, 52: 100, 54: 100, 60: 100, 62: 100, 65: 100, 76: 100, 78: 100, 82: 100, 84: 100, 94: 100, 96: 100}, 53: {11: 100, 13: 100, 17: 100, 24: 100, 26: 100, 31: 100, 32: 100, 40: 100, 43: 100, 53: 100, 59: 100, 66: 100, 73: 100, 74: 100, 75: 100, 77: 100, 80: 100, 84: 100, 85: 100, 99: 100}, 54: {20: 100, 24: 100, 27: 100, 29: 100, 30: 100, 31: 100, 40: 100, 45: 100, 46: 100, 47: 100, 52: 100, 54: 100, 55: 100, 64: 100, 74: 100, 75: 100, 83: 100, 85: 100, 92: 100, 95: 100}, 55: {3: 100, 18: 100, 19: 100, 25: 100, 27: 100, 38: 100, 44: 100, 47: 100, 54: 100, 55: 100, 58: 100, 60: 100, 63: 100, 70: 100, 80: 100, 81: 100, 86: 100, 87: 100, 92: 100, 98: 100}, 56: {2: 100, 5: 100, 6: 100, 17: 100, 20: 100, 22: 100, 30: 100, 33: 100, 34: 100, 41: 100, 44: 100, 52: 100, 56: 100, 59: 100, 68: 100, 77: 100, 79: 100, 83: 100, 90: 100, 98: 100}, 57: {9: 100, 17: 100, 22: 100, 23: 100, 35: 100, 39: 100, 42: 100, 45: 100, 46: 100, 48: 100, 50: 100, 51: 100, 52: 100, 57: 100, 59: 100, 64: 100, 74: 100, 76: 100, 98: 100, 99: 100}, 58: {5: 100, 11: 100, 12: 100, 16: 100, 19: 100, 20: 100, 31: 100, 32: 100, 42: 100, 48: 100, 49: 100, 51: 100, 53: 100, 58: 100, 65: 100, 70: 100, 71: 100, 74: 100, 77: 100, 79: 100}, 59: {0: 100, 8: 100, 20: 100, 21: 100, 30: 100, 31: 100, 35: 100, 36: 100, 39: 100, 49: 100, 54: 100, 58: 100, 59: 100, 63: 100, 67: 100, 70: 100, 83: 100, 88: 100, 95: 100, 99: 100}, 60: {8: 100, 14: 100, 19: 100, 21: 100, 24: 100, 31: 100, 33: 100, 39: 100, 44: 100, 50: 100, 54: 100, 60: 100, 62: 100, 63: 100, 65: 100, 73: 100, 74: 100, 78: 100, 83: 100, 96: 100}, 61: {7: 100, 16: 100, 17: 100, 18: 100, 22: 100, 25: 100, 26: 100, 32: 100, 39: 100, 46: 100, 47: 100, 57: 100, 60: 100, 61: 100, 66: 100, 70: 100, 71: 100, 78: 100, 90: 100, 99: 100}, 62: {2: 100, 8: 100, 14: 100, 15: 100, 21: 100, 22: 100, 23: 100, 34: 100, 37: 100, 45: 100, 46: 100, 49: 100, 52: 100, 55: 100, 57: 100, 62: 100, 70: 100, 74: 100, 91: 100, 98: 100}, 63: {1: 100, 5: 100, 6: 100, 13: 100, 21: 100, 25: 100, 31: 100, 53: 100, 57: 100, 62: 100, 63: 100, 65: 100, 70: 100, 72: 100, 77: 100, 78: 100, 82: 100, 86: 100, 88: 100, 98: 100}, 64: {4: 100, 13: 100, 18: 100, 25: 100, 27: 100, 34: 100, 45: 100, 47: 100, 55: 100, 58: 100, 59: 100, 64: 100, 67: 100, 75: 100, 76: 100, 82: 100, 86: 100, 94: 100, 95: 100, 97: 100}, 65: {4: 100, 14: 100, 15: 100, 17: 100, 18: 100, 19: 100, 25: 100, 35: 100, 40: 100, 53: 100, 54: 100, 57: 100, 60: 100, 65: 100, 75: 100, 82: 100, 83: 100, 92: 100, 94: 100, 97: 100}, 66: {2: 100, 4: 100, 5: 100, 9: 100, 11: 100, 17: 100, 19: 100, 21: 100, 25: 100, 27: 100, 38: 100, 42: 100, 45: 100, 58: 100, 64: 100, 66: 100, 77: 100, 78: 100, 85: 100, 94: 100}, 67: {5: 100, 13: 100, 18: 100, 21: 100, 23: 100, 30: 100, 33: 100, 36: 100, 37: 100, 52: 100, 59: 100, 60: 100, 61: 100, 64: 100, 66: 100, 67: 100, 80: 100, 88: 100, 90: 100, 99: 100}, 68: {8: 100, 17: 100, 22: 100, 26: 100, 27: 100, 43: 100, 46: 100, 50: 100, 57: 100, 62: 100, 65: 100, 68: 100, 71: 100, 74: 100, 83: 100, 84: 100, 89: 100, 90: 100, 91: 100, 98: 100}, 69: {13: 100, 30: 100, 33: 100, 36: 100, 37: 100, 40: 100, 45: 100, 46: 100, 49: 100, 52: 100, 59: 100, 66: 100, 67: 100, 68: 100, 69: 100, 71: 100, 78: 100, 82: 100, 95: 100, 96: 100}, 70: {0: 100, 12: 100, 13: 100, 14: 100, 22: 100, 23: 100, 43: 100, 45: 100, 46: 100, 47: 100, 53: 100, 56: 100, 70: 100, 71: 100, 76: 100, 86: 100, 88: 100, 89: 100, 93: 100, 98: 100}, 71: {0: 100, 5: 100, 13: 100, 14: 100, 18: 100, 21: 100, 30: 100, 31: 100, 32: 100, 35: 100, 37: 100, 55: 100, 56: 100, 59: 100, 71: 100, 74: 100, 75: 100, 78: 100, 85: 100, 91: 100}, 72: {2: 100, 3: 100, 5: 100, 13: 100, 15: 100, 17: 100, 22: 100, 23: 100, 29: 100, 36: 100, 48: 100, 52: 100, 56: 100, 59: 100, 60: 100, 63: 100, 72: 100, 83: 100, 89: 100, 90: 100}, 73: {16: 100, 18: 100, 20: 100, 21: 100, 27: 100, 30: 100, 42: 100, 49: 100, 53: 100, 54: 100, 58: 100, 67: 100, 68: 100, 70: 100, 72: 100, 73: 100, 80: 100, 85: 100, 90: 100, 93: 100}, 74: {0: 100, 8: 100, 9: 100, 10: 100, 11: 100, 12: 100, 13: 100, 20: 100, 21: 100, 23: 100, 24: 100, 25: 100, 50: 100, 56: 100, 65: 100, 71: 100, 74: 100, 84: 100, 85: 100, 95: 100}, 75: {0: 100, 6: 100, 7: 100, 12: 100, 17: 100, 31: 100, 38: 100, 45: 100, 48: 100, 51: 100, 59: 100, 68: 100, 70: 100, 71: 100, 72: 100, 75: 100, 78: 100, 84: 100, 94: 100, 98: 100}, 76: {1: 100, 5: 100, 12: 100, 14: 100, 37: 100, 42: 100, 43: 100, 46: 100, 49: 100, 55: 100, 57: 100, 58: 100, 62: 100, 65: 100, 68: 100, 76: 100, 78: 100, 83: 100, 98: 100, 99: 100}, 77: {1: 100, 11: 100, 13: 100, 20: 100, 22: 100, 23: 100, 28: 100, 31: 100, 40: 100, 42: 100, 50: 100, 56: 100, 58: 100, 59: 100, 64: 100, 65: 100, 76: 100, 77: 100, 83: 100, 89: 100}, 78: {1: 100, 8: 100, 24: 100, 26: 100, 27: 100, 28: 100, 31: 100, 34: 100, 35: 100, 42: 100, 46: 100, 51: 100, 59: 100, 64: 100, 70: 100, 72: 100, 78: 100, 82: 100, 83: 100, 86: 100}, 79: {0: 100, 18: 100, 19: 100, 21: 100, 28: 100, 33: 100, 40: 100, 42: 100, 57: 100, 58: 100, 61: 100, 79: 100, 81: 100, 83: 100, 90: 100, 91: 100, 93: 100, 94: 100, 97: 100, 99: 100}, 80: {5: 100, 9: 100, 12: 100, 13: 100, 18: 100, 25: 100, 35: 100, 37: 100, 39: 100, 47: 100, 49: 100, 50: 100, 55: 100, 72: 100, 75: 100, 80: 100, 84: 100, 85: 100, 88: 100, 93: 100}, 81: {7: 100, 11: 100, 12: 100, 13: 100, 16: 100, 17: 100, 20: 100, 25: 100, 32: 100, 48: 100, 53: 100, 59: 100, 62: 100, 71: 100, 72: 100, 76: 100, 81: 100, 87: 100, 94: 100, 96: 100}, 82: {1: 100, 2: 100, 4: 100, 7: 100, 8: 100, 17: 100, 19: 100, 25: 100, 33: 100, 41: 100, 50: 100, 59: 100, 68: 100, 78: 100, 82: 100, 84: 100, 85: 100, 91: 100, 98: 100, 99: 100}, 83: {6: 100, 13: 100, 16: 100, 21: 100, 22: 100, 30: 100, 32: 100, 33: 100, 41: 100, 42: 100, 59: 100, 64: 100, 65: 100, 70: 100, 75: 100, 78: 100, 83: 100, 85: 100, 89: 100, 94: 100}, 84: {6: 100, 14: 100, 16: 100, 19: 100, 21: 100, 24: 100, 25: 100, 26: 100, 31: 100, 37: 100, 45: 100, 56: 100, 69: 100, 72: 100, 75: 100, 77: 100, 84: 100, 85: 100, 93: 100, 94: 100}, 85: {10: 100, 11: 100, 13: 100, 16: 100, 30: 100, 31: 100, 32: 100, 33: 100, 34: 100, 36: 100, 37: 100, 44: 100, 49: 100, 64: 100, 66: 100, 81: 100, 85: 100, 91: 100, 93: 100, 97: 100}, 86: {11: 100, 23: 100, 35: 100, 37: 100, 40: 100, 48: 100, 51: 100, 58: 100, 63: 100, 69: 100, 73: 100, 83: 100, 84: 100, 86: 100, 88: 100, 89: 100, 95: 100, 97: 100, 98: 100, 99: 100}, 87: {10: 100, 20: 100, 21: 100, 24: 100, 25: 100, 29: 100, 33: 100, 35: 100, 52: 100, 55: 100, 61: 100, 63: 100, 67: 100, 72: 100, 77: 100, 82: 100, 83: 100, 87: 100, 90: 100, 93: 100}, 88: {2: 100, 8: 100, 10: 100, 20: 100, 27: 100, 29: 100, 36: 100, 37: 100, 39: 100, 49: 100, 53: 100, 57: 100, 62: 100, 63: 100, 64: 100, 65: 100, 71: 100, 73: 100, 78: 100, 88: 100}, 89: {1: 100, 3: 100, 10: 100, 15: 100, 17: 100, 20: 100, 28: 100, 32: 100, 33: 100, 36: 100, 50: 100, 53: 100, 56: 100, 74: 100, 77: 100, 81: 100, 83: 100, 88: 100, 89: 100, 97: 100}, 90: {2: 100, 6: 100, 9: 100, 10: 100, 15: 100, 19: 100, 20: 100, 26: 100, 31: 100, 37: 100, 40: 100, 44: 100, 49: 100, 61: 100, 72: 100, 78: 100, 79: 100, 90: 100, 92: 100, 96: 100}, 91: {4: 100, 6: 100, 19: 100, 22: 100, 27: 100, 32: 100, 33: 100, 35: 100, 42: 100, 48: 100, 60: 100, 61: 100, 75: 100, 82: 100, 83: 100, 86: 100, 88: 100, 89: 100, 91: 100, 99: 100}, 92: {5: 100, 10: 100, 17: 100, 21: 100, 32: 100, 44: 100, 46: 100, 51: 100, 52: 100, 61: 100, 62: 100, 63: 100, 66: 100, 68: 100, 71: 100, 75: 100, 77: 100, 80: 100, 86: 100, 92: 100}, 93: {7: 100, 8: 100, 13: 100, 30: 100, 38: 100, 47: 100, 53: 100, 56: 100, 57: 100, 58: 100, 63: 100, 65: 100, 69: 100, 73: 100, 74: 100, 77: 100, 84: 100, 93: 100, 97: 100, 98: 100}, 94: {4: 100, 6: 100, 8: 100, 12: 100, 15: 100, 23: 100, 24: 100, 33: 100, 39: 100, 45: 100, 57: 100, 64: 100, 78: 100, 79: 100, 81: 100, 84: 100, 88: 100, 92: 100, 94: 100, 98: 100}, 95: {17: 100, 21: 100, 22: 100, 35: 100, 42: 100, 47: 100, 51: 100, 61: 100, 69: 100, 73: 100, 75: 100, 76: 100, 82: 100, 83: 100, 85: 100, 87: 100, 89: 100, 94: 100, 95: 100, 99: 100}, 96: {5: 100, 11: 100, 15: 100, 17: 100, 23: 100, 29: 100, 30: 100, 33: 100, 34: 100, 38: 100, 40: 100, 41: 100, 51: 100, 59: 100, 64: 100, 83: 100, 89: 100, 92: 100, 93: 100, 96: 100}, 97: {3: 100, 16: 100, 17: 100, 19: 100, 20: 100, 31: 100, 42: 100, 44: 100, 47: 100, 56: 100, 59: 100, 66: 100, 79: 100, 81: 100, 82: 100, 83: 100, 89: 100, 95: 100, 97: 100, 99: 100}, 98: {7: 100, 17: 100, 27: 100, 28: 100, 29: 100, 41: 100, 48: 100, 56: 100, 64: 100, 69: 100, 73: 100, 74: 100, 78: 100, 80: 100, 84: 100, 87: 100, 89: 100, 90: 100, 91: 100, 98: 100}, 99: {0: 100, 8: 100, 19: 100, 24: 100, 31: 100, 39: 100, 44: 100, 48: 100, 49: 100, 52: 100, 57: 100, 59: 100, 65: 100, 69: 100, 73: 100, 88: 100, 91: 100, 94: 100, 95: 100, 99: 100}} \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "print(f'Loading {args.dataset}, {args.partition} for all clients')\n",
    "\n",
    "args.local_view = True\n",
    "X_train, y_train, X_test, y_test, net_dataidx_map, net_dataidx_map_test, \\\n",
    "traindata_cls_counts, testdata_cls_counts = partition_data(args.dataset, \n",
    "args.datadir, args.logdir, args.partition, args.num_users, beta=args.beta, local_view=args.local_view)\n",
    "\n",
    "train_dl_global, test_dl_global, train_ds_global, test_ds_global = get_dataloader(args.dataset,\n",
    "                                                                                   args.datadir,\n",
    "                                                                                   args.batch_size,\n",
    "                                                                                   128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prep.0.weight torch.Size([64, 3, 3, 3])\n",
      "prep.0.bias torch.Size([64])\n",
      "prep.1.weight torch.Size([64])\n",
      "prep.1.bias torch.Size([64])\n",
      "layer1_head.0.weight torch.Size([128, 64, 3, 3])\n",
      "layer1_head.0.bias torch.Size([128])\n",
      "layer1_head.1.weight torch.Size([128])\n",
      "layer1_head.1.bias torch.Size([128])\n",
      "layer1_residual.0.0.weight torch.Size([128, 128, 3, 3])\n",
      "layer1_residual.0.0.bias torch.Size([128])\n",
      "layer1_residual.0.1.weight torch.Size([128])\n",
      "layer1_residual.0.1.bias torch.Size([128])\n",
      "layer1_residual.1.0.weight torch.Size([128, 128, 3, 3])\n",
      "layer1_residual.1.0.bias torch.Size([128])\n",
      "layer1_residual.1.1.weight torch.Size([128])\n",
      "layer1_residual.1.1.bias torch.Size([128])\n",
      "layer2.0.weight torch.Size([256, 128, 3, 3])\n",
      "layer2.0.bias torch.Size([256])\n",
      "layer2.1.weight torch.Size([256])\n",
      "layer2.1.bias torch.Size([256])\n",
      "layer3_head.0.weight torch.Size([512, 256, 3, 3])\n",
      "layer3_head.0.bias torch.Size([512])\n",
      "layer3_head.1.weight torch.Size([512])\n",
      "layer3_head.1.bias torch.Size([512])\n",
      "layer3_residual.0.0.weight torch.Size([512, 512, 3, 3])\n",
      "layer3_residual.0.0.bias torch.Size([512])\n",
      "layer3_residual.0.1.weight torch.Size([512])\n",
      "layer3_residual.0.1.bias torch.Size([512])\n",
      "layer3_residual.1.0.weight torch.Size([512, 512, 3, 3])\n",
      "layer3_residual.1.0.bias torch.Size([512])\n",
      "layer3_residual.1.1.weight torch.Size([512])\n",
      "layer3_residual.1.1.bias torch.Size([512])\n",
      "linear.weight torch.Size([100, 512])\n",
      "linear.bias torch.Size([100])\n",
      "6621540\n"
     ]
    }
   ],
   "source": [
    "users_model, net_glob, initial_state_dict, server_state_dict = init_nets(args, dropout_p=0.5, bias=args.bias)\n",
    "\n",
    "total=0\n",
    "for name, param in net_glob.named_parameters():\n",
    "    print(name, param.size())\n",
    "    total += np.prod(param.size())\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(initial_state_dict, 'resnet9-init.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_state_dict = copy.deepcopy(initial_state_dict)\n",
    "net_glob.load_state_dict(initial_state_dict)\n",
    "for model in users_model:\n",
    "    model.load_state_dict(initial_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clients = []\n",
    "for idx in range(args.num_users):\n",
    "    \n",
    "    dataidxs = net_dataidx_map[idx]\n",
    "    if net_dataidx_map_test is None:\n",
    "        dataidx_test = None \n",
    "    else:\n",
    "        dataidxs_test = net_dataidx_map_test[idx]\n",
    "    \n",
    "    noise_level = 0\n",
    "    bs = args.local_bs\n",
    "        \n",
    "    train_dl_local, test_dl_local, train_ds_local, test_ds_local = get_dataloader(args.dataset, \n",
    "                                                                   args.datadir, args.local_bs, 64, \n",
    "                                                                   dataidxs, noise_level, \n",
    "                                                                   dataidxs_test=dataidxs_test)\n",
    "    \n",
    "    clients.append(Client_FedAvg(idx, copy.deepcopy(users_model[idx]), args.local_bs, args.local_ep, \n",
    "               args.lr, args.momentum, args.device, train_dl_local, test_dl_local))\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Starting FL')\n",
    "print('-'*40)\n",
    "start = time.time()\n",
    "\n",
    "loss_train = []\n",
    "clients_local_acc = {i:[] for i in range(args.num_users)}\n",
    "w_locals, loss_locals = [], []\n",
    "glob_acc = []\n",
    "\n",
    "w_glob = copy.deepcopy(initial_state_dict)\n",
    "for iteration in range(args.rounds):\n",
    "        \n",
    "    m = max(int(args.frac * args.num_users), 1)\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    \n",
    "    print(f'----- ROUND {iteration+1} -----') \n",
    "    print(idxs_users)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    for idx in idxs_users:\n",
    "        clients[idx].set_state_dict(copy.deepcopy(w_glob)) \n",
    "                   \n",
    "        loss = clients[idx].train( is_print=False)\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "        \n",
    "    # print loss\n",
    "    loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "    template = '-- Average Train loss {:.3f}'\n",
    "    print(template.format(loss_avg))\n",
    "    \n",
    "    ####### FedAvg ####### START\n",
    "    total_data_points = sum([len(net_dataidx_map[r]) for r in idxs_users])\n",
    "    fed_avg_freqs = [len(net_dataidx_map[r]) / total_data_points for r in idxs_users]\n",
    "    w_locals = []\n",
    "    for idx in idxs_users:\n",
    "        w_locals.append(copy.deepcopy(clients[idx].get_state_dict()))\n",
    "\n",
    "    ww = FedAvg(w_locals, weight_avg=fed_avg_freqs)\n",
    "    w_glob = copy.deepcopy(ww)\n",
    "    net_glob.load_state_dict(copy.deepcopy(ww))\n",
    "    ####### FedAvg ####### END\n",
    "    _, acc = eval_test(net_glob, args, test_dl_global)\n",
    "    \n",
    "    glob_acc.append(acc)\n",
    "    template = \"-- Global Acc: {:.3f}, Global Best Acc: {:.3f}\"\n",
    "    print(template.format(glob_acc[-1], np.max(glob_acc)))\n",
    "    \n",
    "    loss_train.append(loss_avg)\n",
    "    \n",
    "    ## clear the placeholders for the next round\n",
    "    loss_locals.clear()\n",
    "    \n",
    "    ## calling garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "end = time.time()\n",
    "duration = end-start\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(glob_acc[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_acc = []\n",
    "for i in range(args.num_users):\n",
    "    _, acc = clients[i].eval_test()\n",
    "    local_acc.append(acc)\n",
    "    print(f'Client {i}, Acc {acc:.2f}')\n",
    "    \n",
    "print(np.mean(local_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
